{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting fasttext\n",
      "  Using cached fasttext-0.9.2.tar.gz (68 kB)\n",
      "Requirement already satisfied: pybind11>=2.2 in /home/gitpod/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from fasttext) (2.9.2)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /home/gitpod/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from fasttext) (57.4.0)\n",
      "Requirement already satisfied: numpy in /home/gitpod/.pyenv/versions/3.9.7/lib/python3.9/site-packages (from fasttext) (1.23.1)\n",
      "Using legacy 'setup.py install' for fasttext, since package 'wheel' is not installed.\n",
      "Installing collected packages: fasttext\n",
      "    Running setup.py install for fasttext ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed fasttext-0.9.2\n",
      "\u001b[33mWARNING: You are using pip version 21.2.3; however, version 22.1.2 is available.\n",
      "You should consider upgrading via the '/home/gitpod/.pyenv/versions/3.9.7/bin/python3.9 -m pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# !pip install pandas\n",
    "# !pip install nltk\n",
    "!pip install fasttext"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import argparse\n",
    "import xml.etree.ElementTree as ET\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import csv\n",
    "import nltk\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer = nltk.stem.PorterStemmer()\n",
    "\n",
    "categories_file_name = r'/workspace/datasets/product_data/categories/categories_0001_abcat0010000_to_pcmcat99300050000.xml'\n",
    "\n",
    "queries_file_name = r'/workspace/datasets/train.csv'\n",
    "output_file_name = r'/workspace/datasets/labeled_query_data.txt'\n",
    "output_train_file_name = r'/workspace/datasets/train'\n",
    "output_test_file_name = r'/workspace/datasets/test'\n",
    "\n",
    "\n",
    "# parser = argparse.ArgumentParser(description='Process arguments.')\n",
    "# general = parser.add_argument_group(\"general\")\n",
    "# general.add_argument(\"--min_queries\", default=1,  help=\"The minimum number of queries per category label (default is 1)\")\n",
    "# general.add_argument(\"--output\", default=output_file_name, help=\"the file to output to\")\n",
    "\n",
    "# args = parser.parse_args()\n",
    "# output_file_name = args.output\n",
    "\n",
    "# if args.min_queries:\n",
    "#     min_queries = int(args.min_queries)\n",
    "\n",
    "# The root category, named Best Buy with id cat00000, doesn't have a parent.\n",
    "root_category_id = 'cat00000'\n",
    "\n",
    "tree = ET.parse(categories_file_name)\n",
    "root = tree.getroot()\n",
    "\n",
    "# Parse the category XML file to map each category id to its parent category id in a dataframe.\n",
    "categories = []\n",
    "parents = []\n",
    "for child in root:\n",
    "    id = child.find('id').text\n",
    "    cat_path = child.find('path')\n",
    "    cat_path_ids = [cat.find('id').text for cat in cat_path]\n",
    "    leaf_id = cat_path_ids[-1]\n",
    "    if leaf_id != root_category_id:\n",
    "        categories.append(leaf_id)\n",
    "        parents.append(cat_path_ids[-2])\n",
    "parents_df = pd.DataFrame(list(zip(categories, parents)), columns =['category', 'parent'])\n",
    "df = pd.read_csv(queries_file_name)[['category', 'query']]\n",
    "df = df[df['category'].isin(categories)]\n",
    "# IMPLEMENT ME: Convert queries to lowercase, and optionally implement other normalization, like stemming.\n",
    "df[\"query\"] =  df[\"query\"].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try converting the queries to lowercase, stripping quotation marks, and removing any other punctuation or unusual characters. Treat anything thatâ€™s not a number or letter as a space, and trim multiple spaces to a single space. Optionally, use the nltk stemmer to stem the queries. If you see any other opportunities to normalize the queries, go for it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>category</th>\n",
       "      <th>query</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abcat0101001</td>\n",
       "      <td>televisiones panasonic  50 pulgadas</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>abcat0101001</td>\n",
       "      <td>sharp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>pcmcat193100050014</td>\n",
       "      <td>nook</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>abcat0101001</td>\n",
       "      <td>rca</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>abcat0101005</td>\n",
       "      <td>rca</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             category                                query\n",
       "0        abcat0101001  televisiones panasonic  50 pulgadas\n",
       "1        abcat0101001                                sharp\n",
       "2  pcmcat193100050014                                 nook\n",
       "3        abcat0101001                                  rca\n",
       "4        abcat0101005                                  rca"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "regexes = [(r\"[\\+]\", \" plus\"),\n",
    "(r\"\\$(\\d+)\", r\"\\1 dollars\"),\n",
    "(r\"\\&\", \" and \"),\n",
    "(r\"\\s*[\\./_-]\\s*\", \" \"),\n",
    "(r\"[^\\w\\s]\", \"\")]\n",
    "\n",
    "for regex, replace in regexes:\n",
    "    df[\"query\"] = df[\"query\"].str.replace(regex, replace, regex = True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/workspace/search_with_machine_learning_course/week3/test_workspace.ipynb Cell 6\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://maxharringt-searchwithm-oy7e03dftx6.ws-us53.gitpod.io/workspace/search_with_machine_learning_course/week3/test_workspace.ipynb#ch0000005vscode-remote?line=0'>1</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39;49m\u001b[39mquery\u001b[39;49m\u001b[39m\"\u001b[39;49m]\u001b[39m.\u001b[39;49mapply(\u001b[39mlambda\u001b[39;49;00m x: stemmer\u001b[39m.\u001b[39;49mstem(x))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/pandas/core/series.py:4433\u001b[0m, in \u001b[0;36mSeries.apply\u001b[0;34m(self, func, convert_dtype, args, **kwargs)\u001b[0m\n\u001b[1;32m   4323\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mapply\u001b[39m(\n\u001b[1;32m   4324\u001b[0m     \u001b[39mself\u001b[39m,\n\u001b[1;32m   4325\u001b[0m     func: AggFuncType,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4328\u001b[0m     \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs,\n\u001b[1;32m   4329\u001b[0m ) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m DataFrame \u001b[39m|\u001b[39m Series:\n\u001b[1;32m   4330\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m   4331\u001b[0m \u001b[39m    Invoke function on values of Series.\u001b[39;00m\n\u001b[1;32m   4332\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4431\u001b[0m \u001b[39m    dtype: float64\u001b[39;00m\n\u001b[1;32m   4432\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4433\u001b[0m     \u001b[39mreturn\u001b[39;00m SeriesApply(\u001b[39mself\u001b[39;49m, func, convert_dtype, args, kwargs)\u001b[39m.\u001b[39;49mapply()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/pandas/core/apply.py:1088\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1084\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mf, \u001b[39mstr\u001b[39m):\n\u001b[1;32m   1085\u001b[0m     \u001b[39m# if we are a string, try to dispatch\u001b[39;00m\n\u001b[1;32m   1086\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mapply_str()\n\u001b[0;32m-> 1088\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mapply_standard()\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/pandas/core/apply.py:1143\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1137\u001b[0m         values \u001b[39m=\u001b[39m obj\u001b[39m.\u001b[39mastype(\u001b[39mobject\u001b[39m)\u001b[39m.\u001b[39m_values\n\u001b[1;32m   1138\u001b[0m         \u001b[39m# error: Argument 2 to \"map_infer\" has incompatible type\u001b[39;00m\n\u001b[1;32m   1139\u001b[0m         \u001b[39m# \"Union[Callable[..., Any], str, List[Union[Callable[..., Any], str]],\u001b[39;00m\n\u001b[1;32m   1140\u001b[0m         \u001b[39m# Dict[Hashable, Union[Union[Callable[..., Any], str],\u001b[39;00m\n\u001b[1;32m   1141\u001b[0m         \u001b[39m# List[Union[Callable[..., Any], str]]]]]\"; expected\u001b[39;00m\n\u001b[1;32m   1142\u001b[0m         \u001b[39m# \"Callable[[Any], Any]\"\u001b[39;00m\n\u001b[0;32m-> 1143\u001b[0m         mapped \u001b[39m=\u001b[39m lib\u001b[39m.\u001b[39;49mmap_infer(\n\u001b[1;32m   1144\u001b[0m             values,\n\u001b[1;32m   1145\u001b[0m             f,  \u001b[39m# type: ignore[arg-type]\u001b[39;49;00m\n\u001b[1;32m   1146\u001b[0m             convert\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mconvert_dtype,\n\u001b[1;32m   1147\u001b[0m         )\n\u001b[1;32m   1149\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mlen\u001b[39m(mapped) \u001b[39mand\u001b[39;00m \u001b[39misinstance\u001b[39m(mapped[\u001b[39m0\u001b[39m], ABCSeries):\n\u001b[1;32m   1150\u001b[0m     \u001b[39m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[1;32m   1151\u001b[0m     \u001b[39m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[1;32m   1152\u001b[0m     \u001b[39mreturn\u001b[39;00m obj\u001b[39m.\u001b[39m_constructor_expanddim(\u001b[39mlist\u001b[39m(mapped), index\u001b[39m=\u001b[39mobj\u001b[39m.\u001b[39mindex)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/pandas/_libs/lib.pyx:2870\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[0;34m()\u001b[0m\n",
      "\u001b[1;32m/workspace/search_with_machine_learning_course/week3/test_workspace.ipynb Cell 6\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://maxharringt-searchwithm-oy7e03dftx6.ws-us53.gitpod.io/workspace/search_with_machine_learning_course/week3/test_workspace.ipynb#ch0000005vscode-remote?line=0'>1</a>\u001b[0m df[\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m df[\u001b[39m\"\u001b[39m\u001b[39mquery\u001b[39m\u001b[39m\"\u001b[39m]\u001b[39m.\u001b[39mapply(\u001b[39mlambda\u001b[39;00m x: stemmer\u001b[39m.\u001b[39;49mstem(x))\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/nltk/stem/porter.py:672\u001b[0m, in \u001b[0;36mPorterStemmer.stem\u001b[0;34m(self, word, to_lowercase)\u001b[0m\n\u001b[1;32m    670\u001b[0m stem \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step1b(stem)\n\u001b[1;32m    671\u001b[0m stem \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step1c(stem)\n\u001b[0;32m--> 672\u001b[0m stem \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_step2(stem)\n\u001b[1;32m    673\u001b[0m stem \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step3(stem)\n\u001b[1;32m    674\u001b[0m stem \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step4(stem)\n",
      "File \u001b[0;32m~/.pyenv/versions/3.9.7/lib/python3.9/site-packages/nltk/stem/porter.py:474\u001b[0m, in \u001b[0;36mPorterStemmer._step2\u001b[0;34m(self, word)\u001b[0m\n\u001b[1;32m    469\u001b[0m     \u001b[39mif\u001b[39;00m word\u001b[39m.\u001b[39mendswith(\u001b[39m\"\u001b[39m\u001b[39malli\u001b[39m\u001b[39m\"\u001b[39m) \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_positive_measure(\n\u001b[1;32m    470\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replace_suffix(word, \u001b[39m\"\u001b[39m\u001b[39malli\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m    471\u001b[0m     ):\n\u001b[1;32m    472\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_step2(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_replace_suffix(word, \u001b[39m\"\u001b[39m\u001b[39malli\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mal\u001b[39m\u001b[39m\"\u001b[39m))\n\u001b[0;32m--> 474\u001b[0m bli_rule \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mbli\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mble\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_has_positive_measure)\n\u001b[1;32m    475\u001b[0m abli_rule \u001b[39m=\u001b[39m (\u001b[39m\"\u001b[39m\u001b[39mabli\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mable\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_positive_measure)\n\u001b[1;32m    477\u001b[0m rules \u001b[39m=\u001b[39m [\n\u001b[1;32m    478\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mational\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mate\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_positive_measure),\n\u001b[1;32m    479\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mtional\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mtion\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_positive_measure),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    497\u001b[0m     (\u001b[39m\"\u001b[39m\u001b[39mbiliti\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39m\"\u001b[39m\u001b[39mble\u001b[39m\u001b[39m\"\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_has_positive_measure),\n\u001b[1;32m    498\u001b[0m ]\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "df[\"query\"] = df[\"query\"].apply(lambda x: stemmer.stem(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "category\n",
       "abcat0010000                  cat00000\n",
       "abcat0011000              abcat0010000\n",
       "abcat0011001              abcat0011000\n",
       "abcat0011002              abcat0011000\n",
       "abcat0011003              abcat0011000\n",
       "                           ...        \n",
       "pcmcat97200050015             cat15063\n",
       "pcmcat99000050001    pcmcat50000050006\n",
       "pcmcat99000050002    pcmcat99000050001\n",
       "pcmcat99300050000             cat15063\n",
       "cat00000                      cat00000\n",
       "Name: parent, Length: 4640, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parents_dict = parents_df.set_index(\"category\")[\"parent\"]\n",
    "parents_dict[\"cat00000\"] = \"cat00000\"\n",
    "parents_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "category_cutoff_count = 10000\n",
    "\n",
    "def categories_below_cutoff():\n",
    "    return (df[\"category\"].value_counts()<category_cutoff_count).sum()\n",
    "\n",
    "num_of_categories_below_cutoff = categories_below_cutoff()\n",
    "while num_of_categories_below_cutoff > 0:\n",
    "    categories_below = df[\"category\"].value_counts().where(lambda x: x<category_cutoff_count).dropna()\n",
    "    df[\"category\"] = df[\"category\"].apply(lambda x: parents_dict[x] if x in categories_below else x)\n",
    "    num_of_categories_below_cutoff = categories_below_cutoff()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['label'] = '__label__' + df['category']\n",
    "\n",
    "# Output labeled query data as a space-separated file, making sure that every category is in the taxonomy.\n",
    "df = df[df['category'].isin(categories)]\n",
    "df['output'] = df['label'] + ' ' + df['query']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[['output']].sample(frac = 0.8)\n",
    "test = df[[\"output\"]].drop(train.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "__label__cat02015              177638\n",
       "__label__abcat0101001           80213\n",
       "__label__pcmcat247400050000     79245\n",
       "__label__pcmcat209000050008     74258\n",
       "__label__abcat0900000           69044\n",
       "                                ...  \n",
       "__label__abcat0703001           10400\n",
       "__label__abcat0301014           10387\n",
       "__label__pcmcat164200050013     10187\n",
       "__label__abcat0715001           10144\n",
       "__label__pcmcat186100050006     10051\n",
       "Name: label, Length: 69, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(('__label__abcat0101001',\n",
       "  '__label__pcmcat200900050015',\n",
       "  '__label__abcat0106004'),\n",
       " array([0.98524475, 0.00435535, 0.00350147]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import fasttext\n",
    "model = fasttext.load_model(\"/workspace/search_with_machine_learning_course/week3/model2.bin\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'__label__cat09000 OR __label__pcmcat143700050032 OR __label__pcmcat219900050000 OR __label__cat02015 OR __label__abcat0500000 OR __label__abcat0301014 OR __label__abcat0201007'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "categories, probs = model.predict('car', k = 69)\n",
    "#### W3: create filters and boosts\n",
    "threshold = 0.5\n",
    "for i in range(69):\n",
    "    if sum(probs[0:i])> threshold:\n",
    "        categories = categories[0:i]\n",
    "        break\n",
    "\" OR \".join(categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('__label__abcat0101001',\n",
       " '__label__pcmcat200900050015',\n",
       " '__label__abcat0106004',\n",
       " '__label__abcat0101005',\n",
       " '__label__cat02015',\n",
       " '__label__abcat0100000',\n",
       " '__label__abcat0106005',\n",
       " '__label__pcmcat143200050016',\n",
       " '__label__pcmcat233200050010',\n",
       " '__label__pcmcat200900050014',\n",
       " '__label__abcat0107020',\n",
       " '__label__abcat0303000',\n",
       " '__label__pcmcat200900050008',\n",
       " '__label__abcat0102008',\n",
       " '__label__abcat0500000',\n",
       " '__label__pcmcat158900050018',\n",
       " '__label__pcmcat143700050048',\n",
       " '__label__pcmcat128700050041',\n",
       " '__label__abcat0200000',\n",
       " '__label__pcmcat158400050073',\n",
       " '__label__abcat0106015',\n",
       " '__label__abcat0106001',\n",
       " '__label__abcat0102003',\n",
       " '__label__pcmcat186100050006',\n",
       " '__label__abcat0805000',\n",
       " '__label__pcmcat144700050004',\n",
       " '__label__abcat0102005',\n",
       " '__label__abcat0515004',\n",
       " '__label__abcat0201011',\n",
       " '__label__pcmcat242800050021',\n",
       " '__label__abcat0106016',\n",
       " '__label__abcat0403004',\n",
       " '__label__abcat0107040',\n",
       " '__label__pcmcat206100050021',\n",
       " '__label__pcmcat208100050009',\n",
       " '__label__pcmcat221000050010',\n",
       " '__label__pcmcat159300050002',\n",
       " '__label__pcmcat139300050000',\n",
       " '__label__abcat0901004',\n",
       " '__label__pcmcat175600050018',\n",
       " '__label__abcat0903003',\n",
       " '__label__pcmcat233600050006',\n",
       " '__label__pcmcat247400050000',\n",
       " '__label__abcat0915000',\n",
       " '__label__pcmcat167300050040',\n",
       " '__label__pcmcat219900050000',\n",
       " '__label__abcat0901005',\n",
       " '__label__abcat0410029',\n",
       " '__label__abcat0905001',\n",
       " '__label__abcat0410022',\n",
       " '__label__abcat0503007',\n",
       " '__label__abcat0403000',\n",
       " '__label__pcmcat158900050019',\n",
       " '__label__abcat0507002',\n",
       " '__label__abcat0307026',\n",
       " '__label__pcmcat277400050005',\n",
       " '__label__pcmcat186100050007',\n",
       " '__label__abcat0912000',\n",
       " '__label__pcmcat209000050008',\n",
       " '__label__abcat0102007')"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('3.9.7')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "2179da26460779b72e9d4db78d1f0d25627d1420235989e6acfeab7cd7b3c8a5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
